{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SFM_Starter.ipynb",
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/itberrios/think_autonomous/blob/main/3d_reconstruction/SFM_Starter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Welcome to Structure From Motion!\n",
        "This is the final step â€” and one of the most exciting project you can build in 3D Computer Vision!\n",
        "\n",
        "Here's what we're going to do:\n",
        "\n",
        "*   Load 2 or more images\n",
        "*   Match Features\n",
        "*   Estimate the Fundamental Matrix\n",
        "*   Estimate the Essential Matrix\n",
        "*   Recover R and T\n",
        "*   Triangulate\n",
        "*   Reconstruct in 3D\n",
        "\n"
      ],
      "metadata": {
        "id": "puUJLfpjap7p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k_yrMmskhfTY"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "#%matplotlib notebook\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "#auto-reloading external modules\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://stereo-vision.s3.eu-west-3.amazonaws.com/fountain.zip && unzip fountain.zip"
      ],
      "metadata": {
        "id": "q0gOnXbbhlRw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Images"
      ],
      "metadata": {
        "id": "8TSAoA4HlShC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Reading two images for reference\n",
        "img1 = cv2.imread('fountain/0001.png')\n",
        "img2 = cv2.imread('fountain/0002.png')\n",
        "\n",
        "#Converting from BGR to RGB format\n",
        "img1 = img1[:,:,::-1]\n",
        "img2 = img2[:,:,::-1]\n",
        "\n",
        "#NOTE: you can adjust appropriate figure size according to the size of your screen\n",
        "f, (ax0, ax1) = plt.subplots(1,2,figsize=(9,4))\n",
        "ax0.imshow(img1)\n",
        "ax1.imshow(img2)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "g-sGGsKDhnAh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Feature Matching"
      ],
      "metadata": {
        "id": "OmZJbynJlU3k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sift = cv2.SIFT_create()\n",
        "kp = sift.detect(img2,None)"
      ],
      "metadata": {
        "id": "Ud0skhwgyTAZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sift = cv2.SIFT_create()\n",
        "kp1, des1 = sift.detectAndCompute(img1, None)\n",
        "kp2, des2 = sift.detectAndCompute(img2, None)"
      ],
      "metadata": {
        "id": "8p1DldloyS8j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FLANN parameters\n",
        "FLANN_INDEX_KDTREE = 1\n",
        "index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
        "search_params = dict(checks=50) # or pass empty dictionary\n",
        "flann = cv2.FlannBasedMatcher(index_params,search_params)\n",
        "matches = flann.knnMatch(des1,des2,k=2)"
      ],
      "metadata": {
        "id": "qMWvPM5IzVZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Need to draw only good matches, so create a mask\n",
        "matchesMask = [[0,0] for i in range(len(matches))]\n",
        "# ratio test as per Lowe's paper\n",
        "for i,(m,n) in enumerate(matches):\n",
        " if m.distance < 0.7*n.distance:\n",
        "  matchesMask[i]=[1,0]\n",
        "draw_params = dict(matchColor = (0,255,0),\n",
        " singlePointColor = (255,0,0),\n",
        " matchesMask = matchesMask,\n",
        " flags = cv2.DrawMatchesFlags_DEFAULT)\n",
        "img3 = cv2.drawMatchesKnn(img1,kp1,img2,kp2,matches,None,**draw_params)\n",
        "plt.imshow(img3,),plt.show()"
      ],
      "metadata": {
        "id": "OONOU7KYyS4t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(matches)"
      ],
      "metadata": {
        "id": "I7wtvCEw2Yhd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
        "# Match descriptors.\n",
        "matches = bf.match(des1.astype(np.uint8), des2.astype(np.uint8))\n",
        "# Sort them in the order of their distance.\n",
        "matches = sorted(matches, key = lambda x:x.distance)"
      ],
      "metadata": {
        "id": "QuefH7sC05-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def GetImageMatches(img1,img2, match_type='bf'):\n",
        "    # ref: https://docs.opencv.org/4.x/dc/dc3/tutorial_py_matcher.html\n",
        "    sift = cv2.SIFT_create()\n",
        "    kp1, des1 = sift.detectAndCompute(img1, None)\n",
        "    kp2, des2 = sift.detectAndCompute(img2, None)\n",
        "\n",
        "    if match_type == 'bf':\n",
        "      bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
        "      # Match descriptors.\n",
        "      matches = bf.match(des1.astype(np.uint8), des2.astype(np.uint8))\n",
        "      # Sort them in the order of their distance.\n",
        "      matches = sorted(matches, key = lambda x:x.distance)\n",
        "\n",
        "    # else: # use KNN matching\n",
        "    #   # FLANN parameters\n",
        "    #   FLANN_INDEX_KDTREE = 1\n",
        "    #   index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
        "    #   search_params = dict(checks=50) # or pass empty dictionary\n",
        "    #   flann = cv2.FlannBasedMatcher(index_params,search_params)\n",
        "    #   matches = flann.knnMatch(des1,des2,k=2)\n",
        "\n",
        "    return kp1,des1,kp2,des2,matches\n",
        "\n",
        "def GetAlignedMatches(kp1,desc1,kp2,desc2,matches):\n",
        "    img1idx = np.array([m.queryIdx for m in matches])\n",
        "    img2idx = np.array([m.trainIdx for m in matches])\n",
        "\n",
        "    # filter keypoints that were not matched\n",
        "    kp1_ = (np.array(kp1))[img1idx]\n",
        "    kp2_ = (np.array(kp2))[img2idx]\n",
        "\n",
        "    # retreive image coordinates of amtched keypoints\n",
        "    img1pts = np.array([kp.pt for kp in kp1_])\n",
        "    img2pts = np.array([kp.pt for kp in kp2_])\n",
        "\n",
        "    return img1pts,img2pts,img1idx,img2idx\n",
        "\n",
        "#Getting SIFT/SURF features for image matching (this might take a while)\n",
        "match_type = 'bf'\n",
        "kp1,desc1,kp2,desc2,matches=GetImageMatches(img1, img2, match_type)\n",
        "#kp1,desc1,kp2,desc2,matches, img1pts, img2pts = feature_matching(img1, img2)\n",
        "\n",
        "#Aligning two keypoint vectors\n",
        "img1pts,img2pts,img1idx,img2idx=GetAlignedMatches(kp1, desc1, kp2, desc2, matches)"
      ],
      "metadata": {
        "id": "I-b_8gHahyeZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "draw_params = dict(matchColor = (0,255,0), # draw matches in green color\n",
        "                    singlePointColor = None,\n",
        "                    flags = 2)\n",
        "\n",
        "plt.imshow(cv2.drawMatches(img1,kp1,img2,kp2,matches,None,**draw_params))"
      ],
      "metadata": {
        "id": "ov-EPVvFs1Wm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Estimate Fundamental Matrix"
      ],
      "metadata": {
        "id": "EQEu_OhAlWrZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "F, mask = cv2.findFundamentalMat(img1pts, img2pts, cv2.FM_7POINT) # cv2.FM_RANSACcv2.FM_LMEDS)\n",
        "mask=mask.astype(bool).flatten()"
      ],
      "metadata": {
        "id": "jBQGvC_dljM_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(mask)"
      ],
      "metadata": {
        "id": "QBNFWuAM7rLa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(img1pts))\n",
        "print(len(img2pts))\n",
        "print(len(mask))"
      ],
      "metadata": {
        "id": "xoWx8wkGhnPY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Inliers // Optional\n",
        "img1pts = img1pts[mask==True]\n",
        "img2pts = img2pts[mask==True]\n",
        "mask = len(img1pts) * [True] ### We need the match matrix to be the same size of the number of points"
      ],
      "metadata": {
        "id": "klWsOTFV-ZNW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(img1pts))\n",
        "print(len(img2pts))\n",
        "print(len(mask))"
      ],
      "metadata": {
        "id": "ttV6viLBhI6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compute Epipolar Lines"
      ],
      "metadata": {
        "id": "WVADH0CalyL4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ComputeEpiline(pts, index, F):\n",
        "    if pts.shape[1]==2:\n",
        "        #converting to homogenous coordinates if not already\n",
        "        pts = cv2.convertPointsToHomogeneous(pts)[:,0,:]\n",
        "\n",
        "    if index==1:\n",
        "        lines = F.dot(pts.T)\n",
        "    elif index==2:\n",
        "        lines = F.T.dot(pts.T)\n",
        "\n",
        "    return lines.T"
      ],
      "metadata": {
        "id": "PGpvveAkmnc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lines2=ComputeEpiline(img1pts[mask],1,F)\n",
        "lines1=ComputeEpiline(img2pts[mask],2,F)"
      ],
      "metadata": {
        "id": "ZMVNTlkaltBl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def drawlines(img1,img2,lines,pts1,pts2,drawOnly=None,linesize=7,circlesize=10):\n",
        "    r,c = img1.shape[:-1]\n",
        "\n",
        "    img1_, img2_ = np.copy(img1), np.copy(img2)\n",
        "\n",
        "    drawOnly = lines.shape[0] if (drawOnly is None) else drawOnly\n",
        "\n",
        "    i = 0\n",
        "    for r,pt1,pt2 in zip(lines,pts1,pts2):\n",
        "        color = tuple(np.random.randint(0,255,3).tolist())\n",
        "        x0,y0 = map(int, [0, -r[2]/r[1] ])\n",
        "        x1,y1 = map(int, [c, -(r[2]+r[0]*c)/r[1] ])\n",
        "\n",
        "        img1_ = cv2.line(img1_, (x0,y0), (x1,y1), color,linesize)\n",
        "        img1_ = cv2.circle(img1_,tuple(pt1.astype(int)),circlesize,color,-1)\n",
        "        img2_ = cv2.circle(img2_,tuple(pt2.astype(int)),circlesize,color,-1)\n",
        "\n",
        "        i += 1\n",
        "\n",
        "        if i > drawOnly:\n",
        "            break\n",
        "\n",
        "    return img1_,img2_"
      ],
      "metadata": {
        "id": "eoLoT10dmsH6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epilines1, epilines2 = drawlines(img2,img1,lines2,img2pts[mask],img1pts[mask],drawOnly=10,linesize=18,circlesize=10)\n",
        "epilines3, epilines4 = drawlines(img1,img2,lines1,img1pts[mask],img2pts[mask],drawOnly=10,linesize=18,circlesize=10)\n",
        "\n",
        "epilines12 = np.concatenate((epilines2, epilines1), axis=1)\n",
        "plt.imshow(epilines12)\n",
        "plt.show()\n",
        "\n",
        "epilines34 = np.concatenate((epilines3, epilines4), axis=1)\n",
        "plt.imshow(epilines34)\n",
        "plt.show()\n",
        "\n",
        "epilines = np.concatenate((epilines3, epilines1), axis=1)\n",
        "\n",
        "plt.imshow(epilines)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IG8xyNA5m5Fa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Essential Matrix"
      ],
      "metadata": {
        "id": "HOyYqiETnHUd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img1pts[mask]"
      ],
      "metadata": {
        "id": "4cJmFTnl4v83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ref: https://docs.opencv.org/3.4/d9/d0c/group__calib3d.html#ga0b166d41926a7793ab1c351dbaa9ffd4"
      ],
      "metadata": {
        "id": "f47DFYWe5Rmo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "K = np.array([[2759.48,0,1520.69],[0,2764.16,1006.81],[0,0,1]])\n",
        "E = cv2.findEssentialMat(img1pts[mask],\n",
        "                         img2pts[mask],\n",
        "                         K,\n",
        "                         method=cv2.RANSAC,\n",
        "                         prob=0.95,\n",
        "                         threshold=1e-3,\n",
        "                         maxIters=1000)\n",
        "E = E[0]"
      ],
      "metadata": {
        "id": "nfRYBIKCnYvV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# E = K.T @ F @ K"
      ],
      "metadata": {
        "id": "K6Utrdey7obP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(E)"
      ],
      "metadata": {
        "id": "-ZZ1X1VVkDvq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Camera Poses"
      ],
      "metadata": {
        "id": "kI9LEebwnbUc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pts_rec, r_rec, t_rec, mask_rec = cv2.recoverPose(E, img1pts, img2pts)"
      ],
      "metadata": {
        "id": "IYZcZohVvEfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Triangulation"
      ],
      "metadata": {
        "id": "LnwE16Q9njNV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def GetTriangulatedPts(img1pts,img2pts,K,R,t):\n",
        "    img1ptsHom = cv2.convertPointsToHomogeneous(img1pts)[:,0,:]\n",
        "    img2ptsHom = cv2.convertPointsToHomogeneous(img2pts)[:,0,:]\n",
        "\n",
        "    img1ptsNorm = (np.linalg.inv(K).dot(img1ptsHom.T)).T\n",
        "    img2ptsNorm = (np.linalg.inv(K).dot(img2ptsHom.T)).T\n",
        "\n",
        "    img1ptsNorm = cv2.convertPointsFromHomogeneous(img1ptsNorm)[:,0,:]\n",
        "    img2ptsNorm = cv2.convertPointsFromHomogeneous(img2ptsNorm)[:,0,:]\n",
        "\n",
        "    pts4d = cv2.triangulatePoints(np.eye(3,4),np.hstack((R,t)),img1ptsNorm.T,img2ptsNorm.T)\n",
        "    pts3d = cv2.convertPointsFromHomogeneous(pts4d.T)[:,0,:]\n",
        "\n",
        "    return pts3d"
      ],
      "metadata": {
        "id": "QD-WWXMIndhu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# R1, R2, t = cv2.decomposeEssentialMat(E)"
      ],
      "metadata": {
        "id": "LLtqPGzT8DC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pts3d = GetTriangulatedPts(img1pts,img2pts,K,r_rec, t_rec)"
      ],
      "metadata": {
        "id": "LFn7Vmn6nlLf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Save PLY"
      ],
      "metadata": {
        "id": "_wmErW9vn728"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pts2ply(pts,filename='out.ply'):\n",
        "    f = open(filename,'w')\n",
        "    f.write('ply\\n')\n",
        "    f.write('format ascii 1.0\\n')\n",
        "    f.write('element vertex {}\\n'.format(pts.shape[0]))\n",
        "\n",
        "    f.write('property float x\\n')\n",
        "    f.write('property float y\\n')\n",
        "    f.write('property float z\\n')\n",
        "\n",
        "    f.write('property uchar red\\n')\n",
        "    f.write('property uchar green\\n')\n",
        "    f.write('property uchar blue\\n')\n",
        "\n",
        "    f.write('end_header\\n')\n",
        "\n",
        "    for pt in pts:\n",
        "        f.write('{} {} {} 255 255 255\\n'.format(pt[0],pt[1],pt[2]))\n",
        "    f.close()"
      ],
      "metadata": {
        "id": "JI37xea9nml_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pts2ply(pts3d)"
      ],
      "metadata": {
        "id": "edRatzBRoA7K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Try Loop"
      ],
      "metadata": {
        "id": "oTqRDWc5v2hE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "topologies = collections.OrderedDict()\n",
        "topologies['360'] = tuple(zip((0,1,2,3,4,5,6,7,8,9,10,11),\n",
        "                          (1,2,3,4,5,6,7,8,9,10,11,0)))\n",
        "\n",
        "topologies['overlapping'] = tuple(zip((0,1,2,3,4,5,6,7,8,9),\n",
        "                          (1,2,3,4,5,6,7,8,9,10)))\n",
        "\n",
        "topologies['adjacent'] = tuple(zip((0,2,4,6,8,10),\n",
        "                     (1,3,5,7,9,11)))\n",
        "\n",
        "topologies['skipping_1'] = tuple(zip((0,3,6,9),\n",
        "                 (1,4,7,10)))\n",
        "\n",
        "topologies['skipping_2'] = tuple(zip((0,4,8),\n",
        "                 (1,5,9)))\n",
        "\n",
        "topologies[\"zero\"] = tuple(zip((0,0,0),\n",
        "                 (1,1,1)))"
      ],
      "metadata": {
        "id": "slxC-4Piv4CW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import os\n",
        "\n",
        "# os.rename(\"fountain/00010.png\",\"fountain/0010.png\")\n",
        "# os.rename(\"fountain/00011.png\",\"fountain/0011.png\")\n",
        "images= sorted(glob.glob(\"fountain/*.png\"))\n",
        "\n",
        "print(images)\n",
        "\n",
        "images_cv = [cv2.cvtColor(cv2.imread(img), cv2.COLOR_BGR2RGB) for img in images]"
      ],
      "metadata": {
        "id": "mFburGQexGJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main(K, images_cv, topology):\n",
        "    xyz_global_array = [None]*len(topology)\n",
        "    for pair_index, (left_index,right_index) in enumerate(topology):\n",
        "        print(pair_index)\n",
        "        img1 = images_cv[left_index]\n",
        "        img2 = images_cv[right_index]\n",
        "\n",
        "        # 1. Feature Matching\n",
        "        kp1,desc1,kp2,desc2,matches=GetImageMatches(img1,img2)\n",
        "        img1pts,img2pts,img1idx,img2idx=GetAlignedMatches(kp1,desc1,kp2,desc2,matches)\n",
        "\n",
        "        draw_params = dict(matchColor = (0,255,0), # draw matches in green color\n",
        "                    singlePointColor = None,\n",
        "                    flags = 2)\n",
        "\n",
        "        plt.imshow(cv2.drawMatches(img1,kp1,img2,kp2,matches,None,**draw_params))\n",
        "        plt.show()\n",
        "\n",
        "        #2. Fundamental\n",
        "        F, mask = cv2.findFundamentalMat(img1pts, img2pts, method=cv2.FM_7POINT)\n",
        "        mask=mask.astype(bool).flatten()\n",
        "\n",
        "        #2.2 Inliers // Optional\n",
        "        img1pts = img1pts[mask==True]\n",
        "        img2pts = img2pts[mask==True]\n",
        "        mask = len(img1pts) * [True] ### We need the match matrix to be the same size of the number of points\n",
        "\n",
        "        #3. Essential\n",
        "        E = K.T.dot(F.dot(K))\n",
        "\n",
        "        #4. R, T\n",
        "        #R1,R2,t = ExtractCameraPoses(E)\n",
        "        #t = t[:,np.newaxis]\n",
        "        pts_rec, r_rec, t_rec, mask_rec = cv2.recoverPose(E, img1pts, img2pts)\n",
        "\n",
        "        #5. Triangulate\n",
        "        #pts3d = GetTriangulatedPts(img1pts[mask],img2pts[mask],K,R2,t)\n",
        "        pts3d = GetTriangulatedPts(img1pts[mask],img2pts[mask],K,r_rec,t_rec)\n",
        "\n",
        "        #6. Add to Global Points\n",
        "        xyz_global_array[pair_index] = pts3d\n",
        "\n",
        "    return xyz_global_array\n",
        "\n",
        "full_pts3d = main(K, images_cv, topologies[\"overlapping\"])"
      ],
      "metadata": {
        "id": "G1hXUMDfv4f6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, points in enumerate(full_pts3d):\n",
        "    pts2ply(full_pts3d[idx], \"out_1_{}.ply\".format(idx))"
      ],
      "metadata": {
        "id": "km1aBS5uxqA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xyz = np.vstack(full_pts3d)\n",
        "pts2ply(xyz, \"out_full.ply\")"
      ],
      "metadata": {
        "id": "Xc2JKJKFxl9r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_vWsjVAKxT_-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}