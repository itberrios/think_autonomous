{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jeremy26/neural_optimization_course/blob/main/static_quant_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7985817",
      "metadata": {
        "id": "f7985817"
      },
      "source": [
        "# Imports and useful variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "359b355a",
      "metadata": {
        "id": "359b355a"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from copy import deepcopy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7119ed1",
      "metadata": {
        "id": "e7119ed1"
      },
      "outputs": [],
      "source": [
        "cpu_device = torch.device('cpu')\n",
        "randomInput = torch.rand(1,3,9,9)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c919eedc",
      "metadata": {
        "id": "c919eedc"
      },
      "source": [
        "## Model definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "591134ba",
      "metadata": {
        "id": "591134ba"
      },
      "outputs": [],
      "source": [
        "class demoModule(nn.Module):\n",
        "    def __init__(self) -> None:\n",
        "        super().__init__()\n",
        "        # feature extractor\n",
        "        self.fe = nn.Sequential(\n",
        "                            nn.Conv2d(in_channels=3, out_channels=2, kernel_size=3),\n",
        "                            nn.BatchNorm2d(2),\n",
        "                            nn.ReLU(inplace=True)\n",
        "                        )\n",
        "        \n",
        "        # classifier\n",
        "        self.clf = nn.Sequential(\n",
        "                            nn.Conv2d(in_channels=2, out_channels=4, kernel_size=1),\n",
        "                            nn.BatchNorm2d(4),\n",
        "                            nn.ReLU(inplace=True),\n",
        "                        )\n",
        "\n",
        "        self.avgPool = nn.AdaptiveAvgPool2d((1,1))\n",
        "        self.fc = nn.Linear(4,10)\n",
        "\n",
        "\n",
        "    def forward(self, x : torch.Tensor) -> torch.Tensor:\n",
        "        feature_extractor_out = self.fe(x)\n",
        "        classifier_out = self.clf(feature_extractor_out)\n",
        "        out = self.avgPool(classifier_out)\n",
        "        out = torch.flatten(out,1)\n",
        "        out = self.fc(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "762164e0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "762164e0",
        "outputId": "4bfa6fde-6d74-47a0-affb-9af6763aa944"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 10])\n"
          ]
        }
      ],
      "source": [
        "fp32_model = demoModule()\n",
        "out = fp32_model(randomInput)\n",
        "print(out.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c163ea7",
      "metadata": {
        "id": "6c163ea7"
      },
      "source": [
        "## Static Quantization Steps"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d865b44b",
      "metadata": {
        "id": "d865b44b"
      },
      "source": [
        "### Make a copy, move to cpu, set to inference mode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6cfefced",
      "metadata": {
        "id": "6cfefced"
      },
      "outputs": [],
      "source": [
        "model_to_quantize = deepcopy(fp32_model)\n",
        "model_to_quantize.eval();\n",
        "model_to_quantize.to(cpu_device);"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a2c8127",
      "metadata": {
        "id": "3a2c8127"
      },
      "source": [
        "### Fuse modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23697f27",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23697f27",
        "outputId": "d7de6dec-7e99-4f33-ac3d-22b638350da8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "demoModule(\n",
            "  (fe): Sequential(\n",
            "    (0): Conv2d(3, 2, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "  )\n",
            "  (clf): Sequential(\n",
            "    (0): Conv2d(2, 4, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "  )\n",
            "  (avgPool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=4, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model_to_quantize)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0856b7cf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0856b7cf",
        "outputId": "1413ae80-1a4e-477e-84e2-b22ebd936bc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "demoModule(\n",
            "  (fe): Sequential(\n",
            "    (0): ConvReLU2d(\n",
            "      (0): Conv2d(3, 2, kernel_size=(3, 3), stride=(1, 1))\n",
            "      (1): ReLU(inplace=True)\n",
            "    )\n",
            "    (1): Identity()\n",
            "    (2): Identity()\n",
            "  )\n",
            "  (clf): Sequential(\n",
            "    (0): ConvReLU2d(\n",
            "      (0): Conv2d(2, 4, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (1): ReLU(inplace=True)\n",
            "    )\n",
            "    (1): Identity()\n",
            "    (2): Identity()\n",
            "  )\n",
            "  (avgPool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=4, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "modules_to_fuse = [\n",
        "                    ['fe.0', 'fe.1', 'fe.2'],\n",
        "                    ['clf.0', 'clf.1', 'clf.2']\n",
        "                ]\n",
        "fused_model = torch.quantization.fuse_modules(model_to_quantize, modules_to_fuse, inplace=True)\n",
        "print(fused_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ffed3309",
      "metadata": {
        "id": "ffed3309"
      },
      "source": [
        "### Create stubs for model input and output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e598256",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3e598256",
        "outputId": "b347d6b3-0ec5-4400-ddd1-cd4bad008c4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "quantStubModel(\n",
            "  (quant): QuantStub()\n",
            "  (dequant): DeQuantStub()\n",
            "  (model_fp32): demoModule(\n",
            "    (fe): Sequential(\n",
            "      (0): ConvReLU2d(\n",
            "        (0): Conv2d(3, 2, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (1): Identity()\n",
            "      (2): Identity()\n",
            "    )\n",
            "    (clf): Sequential(\n",
            "      (0): ConvReLU2d(\n",
            "        (0): Conv2d(2, 4, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (1): Identity()\n",
            "      (2): Identity()\n",
            "    )\n",
            "    (avgPool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "    (fc): Linear(in_features=4, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "class quantStubModel(nn.Module):\n",
        "    def __init__(self, model_fp32):\n",
        "        super(quantStubModel, self).__init__()\n",
        "        self.quant = torch.quantization.QuantStub()\n",
        "        self.dequant = torch.quantization.DeQuantStub()        \n",
        "        self.model_fp32 = model_fp32\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.quant(x)\n",
        "        x = self.model_fp32(x)\n",
        "        x = self.dequant(x)\n",
        "        return x\n",
        "\n",
        "# creating nn.Module with stubs for inputs and outputs\n",
        "quant_stubbed_model = quantStubModel(model_fp32=fused_model)\n",
        "print(quant_stubbed_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a4d14a3",
      "metadata": {
        "id": "0a4d14a3"
      },
      "source": [
        "### Quantization config & quantization.prepare() function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "785b9772",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "785b9772",
        "outputId": "2a99e19e-0a6f-4a06-cc49-18a548aaab91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Preparing for quantization, inserting observers ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/ao/quantization/observer.py:174: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
            "  reduce_range will be deprecated in a future release of PyTorch.\"\n"
          ]
        }
      ],
      "source": [
        "# colab requires fbgemm backend\n",
        "use_fbgemm = True\n",
        "\n",
        "if use_fbgemm == True:\n",
        "    # for fbgemm, histogram observer is default config\n",
        "    quantization_config = torch.quantization.get_default_qconfig('fbgemm')\n",
        "    torch.backends.quantized.engine = 'fbgemm'\n",
        "\n",
        "else:\n",
        "    # default is minmax observer\n",
        "    quantization_config = torch.quantization.default_qconfig\n",
        "    torch.backends.quantized.engine = 'qnnpack'\n",
        "        \n",
        "# set the quantization configuration for the model\n",
        "print('### Preparing for quantization, inserting observers ...')\n",
        "quant_stubbed_model.qconfig = quantization_config    \n",
        "torch.quantization.prepare(quant_stubbed_model, inplace=True);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f024dcc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9f024dcc",
        "outputId": "ffd86581-9f94-4186-bd32-5fc1791e254f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){})"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "quantization_config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64495a5a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64495a5a",
        "outputId": "d4f9fa9a-bfdd-49cd-c6cb-c367c56cd69f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "torch.quantization.default_qconfig"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c17ec13",
      "metadata": {
        "id": "1c17ec13"
      },
      "source": [
        "### Calibrate Observer parameters on sample dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b2cf639",
      "metadata": {
        "id": "9b2cf639"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    for i in range(5):\n",
        "        _ = quant_stubbed_model(randomInput)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb382387",
      "metadata": {
        "id": "bb382387"
      },
      "source": [
        "### Call quantization.convert()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8cc1f7a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8cc1f7a",
        "outputId": "b8b96fdb-92a8-4b23-8df3-4e7058984302"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/ao/quantization/observer.py:886: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  src_bin_begin // dst_bin_width, 0, self.dst_nbins - 1\n",
            "/usr/local/lib/python3.7/dist-packages/torch/ao/quantization/observer.py:891: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  src_bin_end // dst_bin_width, 0, self.dst_nbins - 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "quantStubModel(\n",
            "  (quant): Quantize(scale=tensor([0.0078]), zero_point=tensor([0]), dtype=torch.quint8)\n",
            "  (dequant): DeQuantize()\n",
            "  (model_fp32): demoModule(\n",
            "    (fe): Sequential(\n",
            "      (0): QuantizedConvReLU2d(3, 2, kernel_size=(3, 3), stride=(1, 1), scale=0.0052048638463020325, zero_point=0)\n",
            "      (1): Identity()\n",
            "      (2): Identity()\n",
            "    )\n",
            "    (clf): Sequential(\n",
            "      (0): QuantizedConvReLU2d(2, 4, kernel_size=(1, 1), stride=(1, 1), scale=0.007241956889629364, zero_point=0)\n",
            "      (1): Identity()\n",
            "      (2): Identity()\n",
            "    )\n",
            "    (avgPool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "    (fc): QuantizedLinear(in_features=4, out_features=10, scale=0.010852521285414696, zero_point=74, qscheme=torch.per_channel_affine)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "quantized_model = torch.quantization.convert(quant_stubbed_model, inplace=True)\n",
        "print(quantized_model)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "nsq-5aqcLx2Q"
      },
      "id": "nsq-5aqcLx2Q",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "conda(dl)",
      "language": "python",
      "name": "dl"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "static quant tutorial.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}