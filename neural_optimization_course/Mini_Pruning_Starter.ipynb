{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mini_Pruning_Starter.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jeremy26/neural_optimization_course/blob/main/Mini_Pruning_Starter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Welcome to the Pruning Mini-Workshop"
      ],
      "metadata": {
        "id": "nbjHCZxynrjT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vIzeiwxDmmlp"
      },
      "outputs": [],
      "source": [
        "# pruning header import\n",
        "import torch.nn.utils.prune as prune\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "# pruning operations are done in-place, so take a copy of the model / module\n",
        "from copy import deepcopy\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a dummy module to understand pruning techniques\n",
        "fc_test = nn.Linear(10,10)\n",
        "\n",
        "module = deepcopy(fc_test)"
      ],
      "metadata": {
        "id": "Y2Bp0KuUoY2D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# contains `weight` and `bias` parameters\n",
        "print('Before pruning, named_parameters()')\n",
        "print(list(module.named_parameters()))\n",
        "\n",
        "print('Before pruning, named_buffers()')\n",
        "# prior to pruning contains no buffers\n",
        "print(list(module.named_buffers()))"
      ],
      "metadata": {
        "id": "HdvrIBtPm1RW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## L1 Unstructured Pruning"
      ],
      "metadata": {
        "id": "TqqXfnOIoJ4L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Numpy"
      ],
      "metadata": {
        "id": "NOtcDMgao1YK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weight = module.weight.cpu().detach().numpy()\n",
        "print(weight)"
      ],
      "metadata": {
        "id": "w-O_U-qRm4ev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_array = #TODO: Sort the Weights\n",
        "print(sorted_array)"
      ],
      "metadata": {
        "id": "dorfq9ImocVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pruned_array = #TODO: Prune the 30% lowest weights\n",
        "print(pruned_array.astype(int))"
      ],
      "metadata": {
        "id": "DPL6wyxjoeTQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PyTorch"
      ],
      "metadata": {
        "id": "fAi9QcvPn9u0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# l1_unstructured means that weights are pruned according to their `L1_norm`\n",
        "# eg: the following line prunes 30% of weights in module according to their L1 norm\n",
        "\n",
        "#TODO: Call L1 Unstructured Pruning on PyTorch"
      ],
      "metadata": {
        "id": "Rhac1yMXm2ji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# contains `weight_orig` and `bias` parameters\n",
        "print('After pruning, named_parameters()')\n",
        "print(list(module.named_parameters()))\n",
        "\n",
        "# after pruning contains `weight_mask`\n",
        "print('After pruning, named_buffers()')\n",
        "print(list(module.named_buffers()))"
      ],
      "metadata": {
        "id": "l4F02VOdm4cp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## L1 Structured"
      ],
      "metadata": {
        "id": "iWUE25T3oOy-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Numpy"
      ],
      "metadata": {
        "id": "3vBjFy6to6Qn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "module = deepcopy(fc_test)\n",
        "\n",
        "weight = module.weight.cpu().detach().numpy()\n",
        "print(weight)"
      ],
      "metadata": {
        "id": "eb81c7hLo8wq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# finding the L1 norm for each row (equivalent to \n",
        "# total norm of each neuron) and sort them \n",
        "sorted_array = #TODO: Sort the Weights\n",
        "print(sorted_array)"
      ],
      "metadata": {
        "id": "bbKpwwE7pA8a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pruned_array = #TODO: Prune the Weights in Structured Mode"
      ],
      "metadata": {
        "id": "Rnh4AgshpCY6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PyTorch"
      ],
      "metadata": {
        "id": "dd4kk6szo_gU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "module = deepcopy(fc_test)\n",
        "# n denotes the order of `L-norm` to use while pruning\n",
        "# dim indicates which dimension to prune\n",
        "\n",
        "#TODO: Prune 30% Structured with PyTorch"
      ],
      "metadata": {
        "id": "LC2Y8TBrm-AR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We can observe entire rows of weights are set to zero, meaning all \n",
        "# connections to a neuron have been pruned\n",
        "list(module.named_buffers())"
      ],
      "metadata": {
        "id": "l1zD4V2Ym-D4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot"
      ],
      "metadata": {
        "id": "CnOAQFLZpWfp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, (ax1, ax2) = plt.subplots(1,2,figsize=(8, 4))\n",
        "\n",
        "# l1 unstructured pruning\n",
        "module = deepcopy(fc_test)\n",
        "prune.l1_unstructured(module, 'weight', amount=0.3);\n",
        "plot_fc_weight(module, ax1)\n",
        "ax1.set_title('L1 Unstructured Pruning')\n",
        "\n",
        "# l1 Structured pruning\n",
        "module = deepcopy(fc_test)\n",
        "prune.ln_structured(module, 'weight', amount=0.3, n=1, dim=0);\n",
        "plot_fc_weight(module, ax2);\n",
        "ax2.set_title('L1 Structured Pruning');"
      ],
      "metadata": {
        "id": "t5SGLPIMnE9i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, (ax1, ax2) = plt.subplots(1,2,figsize=(8, 4))\n",
        "plot_fc_weight(module.weight, ax1)\n",
        "\n",
        "# l1 unstructured pruning\n",
        "module = deepcopy(fc_test)\n",
        "prune.l1_unstructured(module, 'weight', amount=0.3);\n",
        "plot_fc_weight(module.weight, ax1);\n",
        "ax1.set_title('L1 Unstructured Pruning')\n",
        "\n",
        "# l1 Structured pruning\n",
        "module = deepcopy(fc_test)\n",
        "prune.ln_structured(module, 'weight', amount=0.3, n=1, dim=0);\n",
        "plot_fc_weight(module.weight, ax2);\n",
        "ax2.set_title('L1 Structured Pruning');"
      ],
      "metadata": {
        "id": "U5elOA7Im-KY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}